---
title: "Kernel density estimation"
output:
  pdf_document: default
  html_document: default
header-includes:
- \usepackage{color}
- \usepackage{graphicx}
- \usepackage{epic}
- \usepackage{hyperref}
- \PassOptionsToPackage{pdfmark}{hyperref}\RequirePackage{hyperref}
- \newcommand{\ve}[1]{\mathbf{#1}}
- \newcommand{\pop}[1]{\mathcal{#1}}
- \newcommand{\samp}[1]{\mathcal{#1}}
- \newcommand{\subspace}[1]{\mathcal{#1}}
- \newcommand{\sv}[1]{\boldsymbol{#1}}
- \newcommand{\sm}[1]{\boldsymbol{#1}}
- \newcommand{\tr}[1]{{#1}^{\mkern-1.5mu\mathsf{T}}}
- \newcommand{\abs}[1]{\left\lvert ~{#1} ~\right\rvert}
- \newcommand{\size}[1]{\left\lvert {#1} \right\rvert}
- \newcommand{\norm}[1]{\left|\left|{#1}\right|\right|}
- \newcommand{\field}[1]{\mathbb{#1}}
- \newcommand{\Reals}{\field{R}}
- \newcommand{\Integers}{\field{Z}}
- \newcommand{\Naturals}{\field{N}}
- \newcommand{\Complex}{\field{C}}
- \newcommand{\Rationals}{\field{Q}}
- \newcommand{\widebar}[1]{\overline{#1}}
- \newcommand{\wig}[1]{\tilde{#1}}
- \newcommand{\bigwig}[1]{\widetilde{#1}}
- \newcommand{\leftgiven}{~\left\lvert~}
- \newcommand{\given}{~\vert~}
- \newcommand{\indep}{\bot\hspace{-.6em}\bot}
- \newcommand{\notindep}{\bot\hspace{-.6em}\bot\hspace{-0.75em}/\hspace{.4em}}
- \newcommand{\depend}{\Join}
- \newcommand{\notdepend}{\Join\hspace{-0.9 em}/\hspace{.4em}}
- \newcommand{\imply}{\Longrightarrow}
- \newcommand{\notimply}{\Longrightarrow \hspace{-1.5em}/ \hspace{0.8em}}
- \newcommand*{\intersect}{\cap}
- \newcommand*{\union}{\cup}
- \newcommand{\suchthat}{~:~}
- \newcommand{\st}{~:~}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**17 marks (undergrads)** (plus 4 bonus available)

**21 marks (grads)**  

*Kernel density estimation.* 

a. Recall from the notes the general results on the bias (up to $O(h^4)$) and variance (up to order $O(\frac{h}{n})$) of a "simplified kernel" density estimator.

    i. **(4 marks)** Prove that the following kernel is a ``simplified kernel'' (in the sense of the notes).
        \[ K(w) = \left\{ \begin{array}{lcl}
                          \frac{15}{32}(1-w^2)(3-7w^2) & ~~~ & w\in [-1,1] \\
                          &&\\
                          0 && \text{elsewhere.}
                          \end{array}
                          \right.
                          \]
        we'll show $\int K(w)dw=1~~~\int w K(w)dw=0 ~~~and~0\leq\int w^2K(w)dw < \infty$
        \begin{align*}
            \int K(w)dw&=\int^{\infty}_{-\infty}\frac{15}{32}(1-w^2)(3-7w^2)dw\\
            &=\frac{15}{32}\int^{1}_{-1}(7w^4-10w^2+3)dw\\
            &=\frac{15}{32}(\frac{7}{5}w^5-\frac{10}{3}w^3+3w)|^1_{w=-1}\\
            &=1
        \end{align*}
        
        \begin{align*}
            \int wK(w)dw&=\int^{\infty}_{-\infty}\frac{15}{32}(1-w^2)(3-7w^2)wdw\\
            &=\frac{15}{32}\int^{1}_{-1}(7w^5-10w^3+3w)dw\\
            &=\frac{15}{32}(\frac{7}{6}w^6-\frac{10}{4}w^4+\frac{3}{2}w^2)|^1_{w=-1}\\
            &=0
        \end{align*}

        \begin{align*}
            \int w^2K(w)dw&=\int^{\infty}_{-\infty}\frac{15}{32}(1-w^2)(3-7w^2)w^2dw\\
            &=\frac{15}{32}\int^{1}_{-1}(7w^6-10w^4+3w^2)dw\\
            &=\frac{15}{32}(\frac{7}{7}w^7-\frac{10}{5}w^5+\frac{3}{3}w^3)|^1_{w=-1}\\
            &=0
        \end{align*}

        and we are done

    ii. **(8 marks)** Determine the (approximate) mean squared error (from the slides) of $\tilde{f}_K(x)$ for the above kernel $K$ and for arbitrary $f(x)$.
    
      mse=bias+variance
      
      \begin{align*}
          bias[\tilde f_K(x)]&=\frac{1}{2}\sigma_k^2h^2f^{''}(x)+\frac{1}{6}h^3f^{'''}(x)\int w^3K(w)dw+O(h^4)\\
          &=0+\frac{1}{6}h^3f^{'''}(x)(\frac{7}{8}w^8-\frac{10}{6}w^6+\frac{3}{4}w^4)|^1_{w=-1}+O(h^4)\\
          &=0+O(h^4)
      \end{align*}
      
      
      for variance 
      we need to evaluate $\int K^2(w)dw$
        
      \begin{align*}
          \int K^2(w)dw&=\int^{\infty}_{-\infty}(\frac{15}{32})^2(1-w^2)^2(3-7w^2)^2dw\\
          &=(\frac{15}{32})^2\int^{1}_{-1}((1-2w^2+w^4)(49w^4-42w^2+9))dw\\
          &=\frac{5}{4}
      \end{align*}
      
      
      \begin{align*}
      var[\tilde f_K(x)]&=\frac{1}{nh}f(x)\int K^2(w)dw-\frac{1}{n}[f(x)]^2+O(\frac{h^2}{n})\\
      &=\frac{1}{nh}f(x)*\frac{5}{4}-\frac{1}{n}[f(x)]^2+O(\frac{h^2}{n})\\
      &=\frac{1}{nh}f(x)*\frac{5}{4}-\frac{1}{n}[f(x)]^2+O(\frac{h}{n}) \text{  as h<1, the question ask for }O(\frac{h}{n})\\
      \end{align*}
      \begin{align*}
      mse&=\frac{1}{nh}f(x)*\frac{5}{4}-\frac{1}{n}[f(x)]^2+O(\frac{h}{n})+(O(h^4))^2\\
      &=\frac{1}{n}(\frac{5}{4h}f(x) - f^2(x))+O(\frac{h}{n})+O(h^8)\\
      \end{align*}
    
    iii. **(5 marks)** Determine the case for the above $K$ when the true underlying density $f(x)$ is $N(0,1)$.
      we just put $f_{N(0,1)}$ in the mse equation,
      $$mse=\frac{5}{4hn} (\frac{1}{\sqrt{2\pi}}e^{-0.5x^2})-\frac{1}{n}(\frac{1}{2\pi}e^{-x^2}) +O(\frac{h}{n})+O(h^8)$$
        
b. **Graduate students (bonus undergraduates)** **(4 marks)** 

    Consider the general  ASH estimate (non-naive ASH):
    \[
        \begin{array}{rcl}
        \widehat{f}(x,m) &= &\frac{1}{nh}\sum_{|i| < m}w_m(i)v_{k+i}
        \end{array}
        \] 
    for $x \in B_k$.  Here the weights $w_m(i) \ge 0$ and the intervals $B_j = [b_j, b_{j+1})$ indexed by $j = 0, \pm1, \pm2, \pm3, \ldots$ partition the entire real line.
    
    The intervals are each of width  $(b_{j+1} - b_j ) =  \frac{h}{m}$ and $v_j$ is the number of $x$s in $B_j$.   The total sample size is $n=\sum_{|j|=0}^{\infty}v_j$.
    
    Prove that  if $\sum_{|i| < m}w_m(i)=m$ then $\int \widehat{f}(x,m) dx = 1$.
